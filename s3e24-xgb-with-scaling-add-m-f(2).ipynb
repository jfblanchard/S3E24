{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# S3E24 Notebook\n",
    "* version this: add the gender prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:12.975397562Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q scienceplots\n",
    "!pip install -q catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:14.654726238Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:15.478498393Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:16.252125259Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob, pathlib\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "#import plotly.express as px\n",
    "\n",
    "import scienceplots\n",
    "plt.style.use(['science','no-latex'])  # not sure how to set up latex in kaggle yet.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:19.654377304Z"
    }
   },
   "outputs": [],
   "source": [
    "psg = True\n",
    "\n",
    "if psg:\n",
    "    root_dir = '.'\n",
    "else:\n",
    "    root_dir = '/kaggle/input/playground-series-s3e24'\n",
    "    \n",
    "train = pd.read_csv(root_dir + '/train.csv')\n",
    "test = pd.read_csv(root_dir + '/test.csv')\n",
    "ss = pd.read_csv(root_dir + '/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:23.432442865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'age, height(cm), weight(kg), waist(cm), eyesight(left), eyesight(right), hearing(left), hearing(right), systolic, relaxation, fasting blood sugar, Cholesterol, triglyceride, HDL, LDL, hemoglobin, Urine protein, serum creatinine, AST, ALT, Gtp, dental caries'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = [col for col in test.columns if col !='id']\n",
    "int_features = [col for col in test.columns if 'id' not in col and test[col].dtype=='int']\n",
    "float_features = [col for col in test.columns if test[col].dtype=='float']\n",
    "\n",
    "features = all_features\n",
    "', '.join(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add M/F predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2023-11-07T21:24:24.447393066Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_gndr = joblib.load('/kaggle/input/s3e24-gender-prediction-model/rf_gender_prediction.joblib')\n",
    "model_gndr = joblib.load(root_dir + '/xgb_gndr_model.joblib')\n",
    "\n",
    "train_gndr = model_gndr.predict_proba(train[features])[:,1]\n",
    "test_gndr = model_gndr.predict_proba(test[features])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['gender'] = train_gndr.round().astype('int')\n",
    "test['gender'] = test_gndr.round().astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add to features arrays\n",
    "features.append('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>fasting blood sugar</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>triglyceride</th>\n",
       "      <th>HDL</th>\n",
       "      <th>LDL</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Urine protein</th>\n",
       "      <th>serum creatinine</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>172</td>\n",
       "      <td>300</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>165</td>\n",
       "      <td>65</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>83</td>\n",
       "      <td>147</td>\n",
       "      <td>194</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>126</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>170</td>\n",
       "      <td>75</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>178</td>\n",
       "      <td>197</td>\n",
       "      <td>45</td>\n",
       "      <td>93</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>180</td>\n",
       "      <td>95</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>180</td>\n",
       "      <td>203</td>\n",
       "      <td>38</td>\n",
       "      <td>102</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>76</td>\n",
       "      <td>91</td>\n",
       "      <td>155</td>\n",
       "      <td>87</td>\n",
       "      <td>44</td>\n",
       "      <td>93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>170</td>\n",
       "      <td>55</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>95</td>\n",
       "      <td>101</td>\n",
       "      <td>199</td>\n",
       "      <td>343</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>15.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45</td>\n",
       "      <td>160</td>\n",
       "      <td>55</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>222</td>\n",
       "      <td>153</td>\n",
       "      <td>69</td>\n",
       "      <td>122</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>91</td>\n",
       "      <td>100</td>\n",
       "      <td>282</td>\n",
       "      <td>165</td>\n",
       "      <td>51</td>\n",
       "      <td>198</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>104</td>\n",
       "      <td>243</td>\n",
       "      <td>163</td>\n",
       "      <td>59</td>\n",
       "      <td>150</td>\n",
       "      <td>15.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>50</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>183</td>\n",
       "      <td>27</td>\n",
       "      <td>55</td>\n",
       "      <td>122</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  eyesight(right)  \\\n",
       "0   55         165          60       81.0             0.5              0.6   \n",
       "1   70         165          65       89.0             0.6              0.7   \n",
       "2   20         170          75       81.0             0.4              0.5   \n",
       "3   35         180          95      105.0             1.5              1.2   \n",
       "4   30         165          60       80.5             1.5              1.0   \n",
       "5   50         170          55       51.0             1.2              1.2   \n",
       "6   45         160          55       69.0             1.5              1.2   \n",
       "7   55         155          60       84.5             0.7              0.9   \n",
       "8   40         165          70       89.0             0.7              1.0   \n",
       "9   40         155          50       73.0             1.5              1.5   \n",
       "\n",
       "   hearing(left)  hearing(right)  systolic  relaxation  fasting blood sugar  \\\n",
       "0              1               1       135          87                   94   \n",
       "1              2               2       146          83                  147   \n",
       "2              1               1       118          75                   79   \n",
       "3              1               1       131          88                   91   \n",
       "4              1               1       121          76                   91   \n",
       "5              1               1       146          95                  101   \n",
       "6              1               1       150          88                   84   \n",
       "7              1               1       137          91                  100   \n",
       "8              1               1       130          80                  104   \n",
       "9              1               1       105          70                   64   \n",
       "\n",
       "   Cholesterol  triglyceride  HDL  LDL  hemoglobin  Urine protein  \\\n",
       "0          172           300   40   75        16.5              1   \n",
       "1          194            55   57  126        16.2              1   \n",
       "2          178           197   45   93        17.4              1   \n",
       "3          180           203   38  102        15.9              1   \n",
       "4          155            87   44   93        15.4              1   \n",
       "5          199           343   31   99        15.9              1   \n",
       "6          222           153   69  122        13.0              1   \n",
       "7          282           165   51  198        14.5              1   \n",
       "8          243           163   59  150        15.7              1   \n",
       "9          183            27   55  122        13.2              1   \n",
       "\n",
       "   serum creatinine  AST  ALT  Gtp  dental caries  gender  \n",
       "0               1.0   22   25   27              0       1  \n",
       "1               1.1   27   23   37              1       1  \n",
       "2               0.8   27   31   53              0       1  \n",
       "3               1.0   20   27   30              1       1  \n",
       "4               0.8   19   13   17              0       1  \n",
       "5               0.7   24   42  119              1       1  \n",
       "6               0.7   17   12   16              0       0  \n",
       "7               0.7   16   15   16              0       0  \n",
       "8               0.9   24   21   31              0       1  \n",
       "9               0.7   22   16   14              0       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[features].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train[train['eyesight(left)'] > 9.0] = 0\n",
    "# train[train['eyesight(right)'] > 9.0] = 0\n",
    "\n",
    "# test[test['eyesight(left)'] > 9.0] = 0\n",
    "# test[test['eyesight(right)'] > 9.0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "mm_scaler = MinMaxScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "# swap out which scaler you want here (some people scale inside of CV)\n",
    "train[features] = pd.DataFrame(mm_scaler.fit_transform(train[features]), columns = features)\n",
    "test[features] = pd.DataFrame(mm_scaler.transform(test[features]), columns = features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define y variable\n",
    "y = train['smoking']\n",
    "\n",
    "x_test = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "folds = 5\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if continuous, change predict_proba to predict\n",
    "def run_cv_and_predict(train, test, features, model, seed,verbose=False):\n",
    "    \n",
    "    # initialize arrays \n",
    "    fold_scores = []\n",
    "    oof = np.zeros(train.shape[0])\n",
    "    preds = np.zeros((test.shape[0],folds))\n",
    "\n",
    "    # setup folding strategy\n",
    "    skf = StratifiedKFold(n_splits=folds,random_state = seed,shuffle=True)\n",
    "    # Use KFold if target is continuous\n",
    "    #skf = KFold(n_splits=folds,random_state = seed,shuffle=True)\n",
    "\n",
    "    # start cross validation\n",
    "    cur_fold = 1\n",
    "    for trn_idx, val_idx in skf.split(train[features], y):\n",
    "\n",
    "        # split indicies into train and validation\n",
    "        x_train = train[features].iloc[trn_idx]\n",
    "        y_train = y.iloc[trn_idx]\n",
    "        x_valid = train[features].iloc[val_idx]\n",
    "        y_valid = y.iloc[val_idx]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_train,y_train)\n",
    "\n",
    "        # predict on validation set\n",
    "        fold_preds = model.predict_proba(x_valid)[:,1]\n",
    "        fold_preds = fold_preds.reshape(len(fold_preds)) # sbabwtdt\n",
    "        oof[val_idx] = fold_preds\n",
    "\n",
    "        # Compute scores\n",
    "        fold_score = roc_auc_score(y_valid,fold_preds)  # CHOOSE METRIC HERE\n",
    "        fold_scores.append(fold_score)\n",
    "        if verbose:\n",
    "            print(f'ROC AUC Score, fold {cur_fold}: {fold_score}')\n",
    "\n",
    "        # predict on test set - store all fold preds (take mode later)\n",
    "        test_preds = model.predict_proba(test[features])[:,1]\n",
    "        test_preds = test_preds.reshape(len(test_preds))  # shouldn't have to do this.\n",
    "        preds[:,cur_fold-1] = test_preds  \n",
    "        cur_fold +=1\n",
    "    \n",
    "    # Print mean fold and oof score \n",
    "    oof_score = roc_auc_score(y,oof)\n",
    "    # oof_score = np.sqrt(mean_squared_error(y,oof))\n",
    "    print(f'ROC AUC score: {np.mean(fold_scores):.5f}, Stdev: {np.std(fold_scores):.5f}, OOF score: {oof_score:.5f}')\n",
    "    # print(f'RMSE score: {np.mean(scores):.5f}, Stdev: {np.std(scores):.5f}, OOF score: {oof_score:.5f}')\n",
    "\n",
    "    return (preds,fold_scores,oof_score,oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression   # try CV too\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.84197, Stdev: 0.00183, OOF score: 0.84197\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()#C=10)\n",
    "preds_lr,scores_lr,oof_score_lr,oof_lr = run_cv_and_predict(train,test,features,model_lr,seed)\n",
    "\n",
    "\n",
    "# model.fit(x_train,y_train)\n",
    "# val_preds = model.predict_proba(x_valid)[:,1]  \n",
    "# score = roc_auc_score(y_valid, val_preds)   # make sure true is first\n",
    "# print(f'ROC AUC Score = {score:.5f}')\n",
    "\n",
    "\n",
    "# default lr, no feature engineering, all features, tts = .81622, lb = .81916\n",
    "# int features = .80181, lb = .80703\n",
    "# float features = .76748, lb = .77048\n",
    "# cross validation: .81702, lb = \n",
    "# std scaling helped logreg by alot! = .83371\n",
    "# add gender feature: .84207\n",
    "# better sex preds: .84197, lb = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(5,3.5))\n",
    "# fpr,tpr,_ = roc_curve(y,oof_lr)\n",
    "# plt.plot(fpr,tpr, label=f'AUC = {np.mean(scores_lr):.5}')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('ROC AUC Score for Logistic Regression')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "* Slowest = about 4 min run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model_rf = RandomForestClassifier()\n",
    "\n",
    "# preds_rf,scores_rf,oof_score_rf,oof_rf = run_cv_and_predict(train,test,features,model_rf,seed)\n",
    "\n",
    "# RF default ROC AUC score: 0.85248, Stdev: 0.00173, OOF score: 0.85247, lb = \n",
    "# 4 min run time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost\n",
    "* About 2x speed of RF with current config, 2 min run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 11.2 ms, total: 22.7 ms\n",
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "\n",
    "# results = []\n",
    "# for iters in [500,750,1000,1250,1500]:\n",
    "#     for d in [3,5,6,7,9]:\n",
    "#         for lr in [.001,.005,.01,.025,.05,.1]:\n",
    "#             model_cat = CatBoostClassifier(verbose=0, \n",
    "#                                            iterations=iters,\n",
    "#                                            depth=d,\n",
    "#                                            learning_rate=lr,\n",
    "#                                            task_type='GPU')\n",
    "#             print(f'iters: {iters}, d: {d}, lr: {lr}')\n",
    "#             preds_cat, scores_cat, oof_score_cat, oof_cat = run_cv_and_predict(train,test,features,model_cat,seed,verbose=False)\n",
    "#             results.append([iters,d,lr, np.mean(scores_cat),oof_score_cat])\n",
    "\n",
    "# default ROC AUC score: 0.86531, Stdev: 0.00177, OOF score: 0.86529, lb = \n",
    "# 2 min run time\n",
    "\n",
    "# add gender feature, 1000,.025,6, score = .86874, lb = .87257\n",
    "\n",
    "# best optimization model: 1500,5,0.1, cv = 0.86845, oof = 0.86844  ( a bit lower than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results,columns=['iterations','depth','learning_rate','cv_score','oof_score'])\n",
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_row = results_df[results_df.cv_score == max(results_df.cv_score)]\n",
    "# print(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# # plotly 3d surface\n",
    "# fig = px.scatter_3d(results_df, x='iterations', y='depth', z='learning_rate',color='cv_score',\n",
    "#                    title='Score vs hyperparams')  # scatter of 3 cols of df\n",
    "# #fig.update_traces(marker={'size': 4})  # scene=dict(zaxis=dict(range=[-5, 5]))\n",
    "# fig.show(renderer='notebook')\n",
    "\n",
    "# plotly doesn't show up in gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use static matplotlib since plotly not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re, seaborn as sns\n",
    "# import numpy as np\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# # axes instance\n",
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax = Axes3D(fig, auto_add_to_figure=False)\n",
    "# fig.add_axes(ax)\n",
    "\n",
    "# # get colormap from seaborn\n",
    "# cmap = ListedColormap(sns.color_palette(\"viridis\", 256).as_hex())\n",
    "\n",
    "# # plot\n",
    "# sc = ax.scatter(results_df.iterations, results_df.depth, results_df.learning_rate, s=40, c=results_df.cv_score, marker='o', cmap=cmap, alpha=1)\n",
    "# ax.set_xlabel('Iterations')\n",
    "# ax.set_ylabel('Depth')\n",
    "# ax.set_zlabel('Learning Rate')\n",
    "\n",
    "# # legend\n",
    "# plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\n",
    "# # save\n",
    "# plt.savefig(\"scatter_hue\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "#     param_grid = {\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 5e-3, 2e-1),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 5000,10000),\n",
    "#         'depth': trial.suggest_categorical('depth', [3,5,7,9,11]),\n",
    "#         #\"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "#         #\"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "#         \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "#     }\n",
    "    \n",
    "    \n",
    "    # these are from catboost github\n",
    "    cat_param = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 5e-3, 2e-1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 5000,10000),\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 200),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 9),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        \"eval_metric\": \"Accuracy\",\n",
    "    }\n",
    "\n",
    "    if cat_param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        cat_param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif cat_param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        cat_param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
    "    \n",
    "    \n",
    "    #model = XGBClassifier(**param_grid,tree_method=\"gpu_hist\") #tree_method='hist',device='cuda')\n",
    "    model = CatBoostClassifier(**cat_param,\n",
    "                                verbose=0,\n",
    "                               task_type='GPU')\n",
    "    \n",
    "    # do cross validation - 5 folds\n",
    "    skf = StratifiedKFold(n_splits=folds,random_state = seed,shuffle=True)\n",
    "\n",
    "    # start cross validation\n",
    "    cur_fold = 1\n",
    "    for trn_idx, val_idx in skf.split(train[features], y):\n",
    "\n",
    "        # split indicies into train and validation\n",
    "        x_train = train[features].iloc[trn_idx]\n",
    "        y_train = y.iloc[trn_idx]\n",
    "        x_valid = train[features].iloc[val_idx]\n",
    "        y_valid = y.iloc[val_idx]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_train,y_train)\n",
    "\n",
    "        # predict on validation set\n",
    "        fold_preds = model.predict_proba(x_valid)[:,1]\n",
    "        fold_score = roc_auc_score(y_valid,fold_preds) \n",
    "        scores.append(fold_score)\n",
    "        #print(f'ROC AUC Score, fold {cur_fold}: {fold_score}')\n",
    "\n",
    "        # predict on test set - store all fold preds (take mode later)\n",
    "#         test_preds = model.predict_proba(test[features])[:,1]\n",
    "#         test_preds = test_preds.reshape(len(test_preds))  # shouldn't have to do this.\n",
    "#         preds[:,cur_fold-1] = test_preds \n",
    "        \n",
    "        cur_fold +=1\n",
    "        \n",
    "    print(np.mean(scores))\n",
    "\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8696624690362471\n",
      "0.8675465508365114\n",
      "0.8500613831761206\n",
      "0.8584591379888105\n",
      "0.8693995765841714\n",
      "0.8694768077226435\n",
      "0.8645112675126085\n",
      "0.8653028630405138\n",
      "0.8676171880278318\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the study\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "sampler = TPESampler(seed=1)\n",
    "study = optuna.create_study(study_name=\"catboost\", direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate the trial\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Value: \", best_trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 11/4/23 Trial Results:\n",
    "<pre>Number of finished trials:  20\n",
    "Best trial:\n",
    "  Value:  0.8683187056949443\n",
    "  Params: \n",
    "    learning_rate: 0.11287917716049423\n",
    "    n_estimators: 1528\n",
    "    depth: 5\n",
    "    min_data_in_leaf: 20\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/5/23 Results\n",
    "<pre>\n",
    "Number of finished trials:  20\n",
    "Best trial:\n",
    "  Value:  0.8687640116756683\n",
    "  Params: \n",
    "    learning_rate: 0.061979058943487576\n",
    "    n_estimators: 2099\n",
    "    depth: 5\n",
    "    min_data_in_leaf: 56\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "Number of finished trials:  100\n",
    "Best trial:\n",
    "  Value:  0.8692235364730058\n",
    "  Params: \n",
    "    learning_rate: 0.06588173117955229\n",
    "    n_estimators: 2881\n",
    "    depth: 5\n",
    "    min_data_in_leaf: 33\n",
    "    \n",
    "</pre>\n",
    "\n",
    "## 11/6/23 Results\n",
    "<pre>\n",
    "Number of finished trials:  100\n",
    "Best trial:\n",
    "  Value:  0.8697138329104549\n",
    "  Params: \n",
    "    learning_rate: 0.0452122794667278\n",
    "    n_estimators: 4927\n",
    "    depth: 5\n",
    "    min_data_in_leaf: 100\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "# model_cat = pickle.load(open('/kaggle/input/s3e24-saved-models/catboost_optuna2.pkl', 'rb'))\n",
    "# preds_cat = model_cat.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set1_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# # set 1\n",
    "# model_xgb = XGBClassifier(#lambda=1.9550993816120785,\n",
    "#                           alpha= 5.814007913805305,\n",
    "#                           colsample_bytree= 0.3,\n",
    "#                           subsample= 1.0,\n",
    "#                           learning_rate= 0.0583947767053339,\n",
    "#                           n_estimators= 1070,\n",
    "#                           max_depth= 7,\n",
    "#                           min_child_weight= 64,\n",
    "#                           random_seed=seed,\n",
    "#                          )\n",
    "\n",
    "\n",
    "# set 2\n",
    "model_xgb = XGBClassifier(#lambda=1.9550993816120785,\n",
    "                      alpha= 4.632016934249366,\n",
    "                      colsample_bytree= 0.3,\n",
    "                      subsample= 1.0,\n",
    "                      learning_rate= 0.06313783399677664,\n",
    "                      n_estimators= 1136,\n",
    "                      max_depth= 7,\n",
    "                      min_child_weight= 53,\n",
    "                      random_state=seed\n",
    "                     )\n",
    "\n",
    "# # set 3\n",
    "# model_xgb = XGBClassifier(#lambda=1.9550993816120785,\n",
    "#                       alpha= 7.061,\n",
    "#                       colsample_bytree= 0.3,\n",
    "#                       subsample= 0.8,\n",
    "#                       learning_rate= 0.03416,\n",
    "#                       n_estimators= 1874,\n",
    "#                       max_depth= 7,\n",
    "#                       min_child_weight= 37,\n",
    "#                       random_state=seed\n",
    "#                      )\n",
    "\n",
    "\n",
    "# model_xgb = XGBClassifier(max_depth=4, n_estimators=100, learning_rate=.35)\n",
    "\n",
    "# print(f'learning rate: {lr}')\n",
    "\n",
    "#preds_xgb, scores_xgb, oof_score_xgb, oof_xgb = run_cv_and_predict(train,test,features,model_xgb,seed,verbose=True)\n",
    "\n",
    "# default, ROC AUC score: 0.86121, Stdev: 0.00183, OOF score: 0.86118, lb = .86831\n",
    "# tuning, higher estimators  = decreasing results.  Try just 50, currently 100 is the highest\n",
    "# max depth of 4 is .86147 (highest of 3-9)\n",
    "# lr .1 to .5, highest is .35 at .86160\n",
    "\n",
    "\n",
    "# Optuna run 1: ROC AUC score: 0.86783, Stdev: 0.00167, OOF score: 0.86782\n",
    "# eyesight >9.0 = 0.0, ROC AUC score: 0.86798, Stdev: 0.00245, OOF score: 0.86796\n",
    "\n",
    "# eyesight thing off, std scaler, ROC AUC score: 0.86783, Stdev: 0.00167, OOF score: 0.86782, lb = .87136\n",
    "# eyesight off, mm scaler: tad worse\n",
    "\n",
    "# add gender feature, no eye correction\n",
    "# set 1 hp's: cv = .87247, lb = .87587\n",
    "# set 2 hp's: cv = .87280, lb = .87623\n",
    "# set 3 hp's: cv = .87304, lb = .87610\n",
    "\n",
    "# use better model for sex\n",
    "# set 1 hp's: cv = 0.87255\n",
    "# set 2 hp's: cv = 0.87269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Full model with different random seeds and average results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# results = []\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "    \n",
    "# define the model\n",
    "# model_xgb = XGBClassifier(#lambda=1.9550993816120785,\n",
    "#                       alpha= 4.632016934249366,\n",
    "#                       colsample_bytree= 0.3,\n",
    "#                       subsample= 1.0,\n",
    "#                       learning_rate= 0.06313783399677664,\n",
    "#                       n_estimators= 1136,\n",
    "#                       max_depth= 7,\n",
    "#                       min_child_weight= 53,\n",
    "#                       random_state=i\n",
    "#                      )\n",
    "\n",
    "\n",
    "    \n",
    "#     # fit the model on the whole dataset\n",
    "#     model_xgb.fit(train[features],y)\n",
    "#     # make predictions\n",
    "#     results.append(model_xgb.predict_proba(x_test)[:,1])\n",
    "    \n",
    "# preds_xgb_full = np.mean(results,axis=0)\n",
    "\n",
    "    \n",
    "# 11/02/23 New params, score = .86798\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "* super fast ~= 40 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y lightgbm\n",
    "# !apt-get install -y libboost-all-dev\n",
    "# !git clone --recursive https://github.com/Microsoft/LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# cd LightGBM\n",
    "# rm -r build\n",
    "# mkdir build\n",
    "# cd build\n",
    "# cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
    "# make -j$(nproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd LightGBM/python-package/;python setup.py install --precompile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "# !rm -r LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# best params so far:\n",
    "est = 1000\n",
    "lr = .02\n",
    "d = 3\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for i in range(10):\n",
    "model_lgbm = LGBMClassifier(verbose=0,\n",
    "                            n_estimators=est,\n",
    "                            learning_rate=lr,\n",
    "                            max_depth=d,\n",
    "                            random_state=seed,\n",
    "                            )\n",
    "    \n",
    "\n",
    "#     # now that tuned fit the model on the whole dataset\n",
    "#     model_lgbm.fit(train[features],y)\n",
    "    \n",
    "#     # make predictions\n",
    "#     results.append(model_lgbm.predict_proba(x_test)[:,1])\n",
    "    \n",
    "# preds_lgbm_full = np.mean(results,axis=0)\n",
    "\n",
    "# preds_lgbm, scores_lgbm, oof_score_lgbm, oof_lgbm = run_cv_and_predict(train,test,features,model_lgbm,seed,verbose=True)\n",
    "\n",
    "# default: ROC AUC score: 0.86130, Stdev: 0.00173, OOF score: 0.86128,\n",
    "# default 100 to 200 est: .86253\n",
    "# 200 to 400 est: .86307\n",
    "# 1000,.02,3, score = .86534\n",
    "\n",
    "# add gender feat, cv = .86353\n",
    "# 1000, .02,3: ROC AUC score: 0.86360, Stdev: 0.00150, OOF score: 0.86359"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lgbm.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_np = np.asarray(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = results_np[:,0]\n",
    "# lr = results_np[:,1]\n",
    "# md = results_np[:,2]\n",
    "# score = results_np[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(est,columns=['estimators'])\n",
    "# results_df['learning_rate'] = lr\n",
    "# results_df['max_depth'] = md\n",
    "# results_df['score'] = score\n",
    "\n",
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[results_df.score == np.max(results_df.score)]\n",
    "# max at 144: est 1000, lr = .02, md = 3, score = .86534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv('lgbm_tune1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import random\n",
    "\n",
    "# # model 1\n",
    "# model1 = oof_cat\n",
    "# preds_1 = preds_cat\n",
    "\n",
    "# # models 2\n",
    "# model2 = oof_xgb\n",
    "# preds_2 = preds_xgb\n",
    "\n",
    "# # model 3\n",
    "# model3 = oof_lgbm\n",
    "# preds_3 = preds_lgbm\n",
    "\n",
    "# # model 4\n",
    "# # model4 = oof_hgbc_ens\n",
    "# # preds_4 = hgbc_preds\n",
    "\n",
    "# # model 5\n",
    "# # model5 = oof_lr\n",
    "# # preds_5 = preds_lr\n",
    "\n",
    "# # generate a random mix for a stochastic determination of min\n",
    "# m = []\n",
    "# for i in range(1000):\n",
    "#     # Generate 3 random numbers to make a mix\n",
    "#     a,b,c = random.random(),random.random(),random.random() #, random.random(),random.random()\n",
    "#     total = a + b + c #+ d# + e\n",
    "#     a /= total\n",
    "#     b /= total\n",
    "#     c /= total\n",
    "# #     d /= total\n",
    "# #     e /= total\n",
    "    \n",
    "#     tm_ens = a*model1 + b*model2 + c*model3 # + d*model4# + e*model5\n",
    "#     tm_score = roc_auc_score(y,tm_ens)  # swap out error function here\n",
    "#     m.append([a,b,c, tm_score])\n",
    "    \n",
    "    \n",
    "# three_model = pd.DataFrame(m,columns=['a','b','c','score'])\n",
    "# three_model.head()\n",
    "\n",
    "# # find min/max score\n",
    "# max_row = three_model[three_model.score == three_model.score.max()]\n",
    "\n",
    "# # get ratios\n",
    "# ratio1 = max_row.a.values[0]\n",
    "# ratio2 = max_row.b.values[0]\n",
    "# ratio3 = max_row.c.values[0]\n",
    "# # ratio4 = max_row.d.values[0]\n",
    "# #ratio5 = max_row.e.values[0]\n",
    "\n",
    "# # predictions on test set\n",
    "# preds_ens = ratio1*preds_1 + \\\n",
    "#             ratio2*preds_2 + \\\n",
    "#             ratio3*preds_3 # + \\\n",
    "# #             ratio4*preds_4 + \\\n",
    "# #            ratio5+preds_5.mean(axis=1)\n",
    "\n",
    "\n",
    "# oof_3_model_ens = ratio1*oof_cat + ratio2*oof_xgb + ratio3*oof_lgbm # + ratio4*oof_hgbc_ens\n",
    "# score = roc_auc_score(y,oof_3_model_ens)\n",
    "# print(f'OOF score of ensemble: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plotly 3d surface\n",
    "# fig = px.scatter_3d(three_model, x='a', y='b', z='c',color='score',\n",
    "#                    title='Score vs ratios for 3 model ensemble')  # scatter of 3 cols of df\n",
    "# fig.update_traces(marker={'size': 4})  # scene=dict(zaxis=dict(range=[-5, 5]))\n",
    "# fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# voting_classifier = VotingClassifier(estimators=[\n",
    "#     ('catboost', model_cat),\n",
    "#     ('lgbm', model_lgbm),\n",
    "#     ('xgb', model_xgb)\n",
    "# ], voting='soft')\n",
    "\n",
    "# # voting_classifier.fit(train, y)\n",
    "# # y_pred = voting_classifier.predict(val_X)\n",
    "# # auroc_score = roc_auc_score(val_Y, y_pred)\n",
    "# # print(f\"AUC-ROC score on validation set: {auroc_score}\")\n",
    "\n",
    "# cv_scores = cross_val_score(voting_classifier, train[features], y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "# print(\"Mean AUC-ROC score:\", np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting_classifier.fit(train[features], y)\n",
    "# voting_preds = voting_classifier.predict_proba(x_test[features])[:, 1]\n",
    "\n",
    "# ['smoking'] = test_preds.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Visualization Improvements\n",
    "* rotate plane to coincide with the z=0 plane, like PCA\n",
    "* stack planes with transparency to get another visualization dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort values so best scores are on the top\n",
    "# sorted_3m = three_model.sort_values(by='score',ascending=False)\n",
    "\n",
    "# # take the mean ratios of the top 10 results\n",
    "# a = sorted_3m.a[0:10].mean()\n",
    "# b = sorted_3m.b[0:10].mean()\n",
    "# c = sorted_3m.c[0:10].mean()\n",
    "# #d = sorted_3m.d[0:10].mean()\n",
    "\n",
    "# tot = a + b + c #+ d\n",
    "\n",
    "# # make a prediction using the average of the top 10 ratios\n",
    "# preds_ens = (a/tot)*preds_1.mean(axis=1) + (b/tot)*preds_2.mean(axis=1) + (c/tot)*preds_3.mean(axis=1) # + (d/tot)*preds_4  \n",
    "\n",
    "# oof_3_model_ens = (a/tot)*oof_cat + (b/tot)*oof_xgb + (c/tot)*oof_lgbm # + (d/tot)*oof_hgbc_ens\n",
    "# score = roc_auc_score(y,oof_3_model_ens)\n",
    "# print(f'OOF score of ensemble: {score:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chose Predictions and Submit Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = (preds_xgb_full + preds_lgbm_full)/2\n",
    "preds = preds_cat.mean(axis=1) # + preds_cat)/2\n",
    "#preds = voting_preds\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.smoking = preds\n",
    "ss.to_csv('231107_cat_submission.csv',index=False)\n",
    "ss.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3.5))\n",
    "ss.smoking.plot(kind='hist',bins=50)\n",
    "plt.title('Test Predictions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
